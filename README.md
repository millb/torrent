# Домашнее задание 2

> ⚠️ **Возможны правки в условие задания. Следите за обновлениями в [канале](https://t.me/joinchat/JPDkFHc-O5wzNTgy)**

В этом домашнем задании вам нужно будет написать свой упрощенный аналог BitTorrent. Оценивание будет производиться
исходя из пройденных тестов.

## Что нужно сделать

Нужно написать код для синхронизации файла в P2P сети и упаковать его в виде Docker образа. Весь ваш код и Dockerfile
должен находиться в директории `./solution`.

В итоговом Merge Request допускаются изменения только в файлах в папке `./solution`.

### Файлы с данными

В контейнере с вашей программой будет находиться два следующих файла:

- `/data.bin` - бинарный файл с данными, содержимое которого нужно синхронизовать между узлами
- `/torrent.conf` - JSON-файл с метаданными для синхронизации файла

Пример содержимого файла `/torrent.conf`:

```json
{
  "Peers": [
    "172.31.111.42",
    "172.31.111.69"
  ],
  "FileInfo": {
    "Size": 2048,
    "PartSize": 256,
    "Parts": [
      "b03f0a063a217b3e94f1f87edc160ff1bbce8d3e",
      "4d7180b857206399e220a1bc22a088edd070780c",
      "875036075144403c45922a9c35f5edbb09699de9",
      "3f30ac24f8ae11538e53ce347a46bf7b3d1cb6bb",
      "36dfe08fb663c78241fd3012d898c96ae123c37c",
      "961742a41014c80d792c531ed7deb76d95ff2333",
      "c5d792d7ec1e94b2e06196ce3de4be8b9efbe20d",
      "e430f703896eecb74927fe7f821fa8b6cafc36fd"
    ]
  }
}
```

В этом файле может содержаться информация про размер файла, размер куска и хеши кусков, информация про пиров (в
зависимости от теста, той или иной информации может не быть). Более формально:

- В '.Peers' содержится массив IP-адресов пиров в виде строк
- В '.FileInfo.Size' указан размер файла с данными
- В '.FileInfo.PartSize' указан размер одного куска файла с данными
- В массиве '.FileInfo.Parts' указаны SHA-1 хеши всех кусков файла с данными

Под SHA-1 хешем куска подразумевается SHA-1 сумма байтов файла начиная с позиции `part*partSize` и длиной `partSize`.
Заметим, что длина последнего куска может быть меньше `partSize`, если размер файла не кратен `partSize`. В этом случае
последним куском нужно считать байты начиная с позиции `part*partSize` и заканчивая концом файла. Хеши кусков выступают
в роли индексов для кусков внутри файла и помогают обмениваться самим содержимым файла.

Ваша задача написать код узла, который общается с другими такими же узлами и модифицирует файл `/data.bin` таким
образом, чтобы он соответствовал нужному размеру и подходил под указанные в конфиге хеши. Когда содержимое
файла `/data.bin` во всех контейнерах синхронизировано, все контейнеры останавливаются и происходит полная проверка
файлов. Если во всех контейнерах файл совпадает и соответствует конфигурации, тест считается пройденным.

### Шаблон

Сейчас в директории `./solution` лежит несколько файлов с кодом + Dockerfile. Можно использовать эту заготовку, можно
все удалить и писать с нуля на вашем любимом языке.

Немного про шаблон. В файле `config.py` лежит код для работы с торрент файлом. В файле `storage.py` написан класс для
чтения и записи по блокам в файл с данными (`data.bin`). В файле `utils.py` реализована функция для проверки хеша блока.
С использованием этих классов и функций остается реализовать класс ноды, который будет запускаться из `main.py`.

Официальная документация по использованию TCP сокетов в asyncio: https://docs.python.org/3/library/asyncio-stream.html

## Компоненты задания

Как уже говорилось выше, для успешного прохождение теста нужно синхронизировать файл на всех нодах. В зависимости от
теста и его условий, на каждый тест дается свой таймаут для синхронизации (указан первой строкой в секции с тестом).

Первый тест сделан таким образом, чтобы его можно было легко запустить локально и посмотреть, как ведет себя ваш код.
Последующие тесты запускаются только через написанные скрипты в
testutil ([инструкция по локальному запуску будет ниже](#локальный-запуск-тестов))

### Простой тест на отправку файла с одного узла на другой (1 балл, simple-docker-compose)

**Timeout: 30 seconds**

В этом тесте есть два узла, конфигурация которых описана в docker-compose.yml

У обоих узлов есть `/torrent.conf` файл со всеми данными, но только у одного узла есть `/data.bin` файл, подходящий под
хеши.

В docker-compose.yml указано как именно эти файлы подключены к локальной файловой системе:

- Контейнер seeder, у которого есть нужный файл, подключает такие файлы:
    - ./tmp/data1.bin:/data.bin
    - ./tmp/torrent1.conf:/torrent.conf
- Контейнер leecher, которому нужно скачать файл, подключает такие файлы:
    - ./tmp/data2.bin:/data.bin
    - ./tmp/torrent2.conf:/torrent.conf

Тест считается пройденным, если после запуска следующих команд файлы синхронизируются:

```bash
# Создать Docker образ из решения, которое лежит в папке ./solution 
docker-compose build

# Удалить контейнеры, которые могли остаться от прошлых запусков
docker-compose down -v

# Очистить содержимое файла
> ./tmp/data2.bin
ctrl+d

# Запустить все контейнеры. После запуска нужно подождать 30c, и нажать Ctrl+C для остановки
docker-compose up

# Проверить содержимое файлов
diff ./tmp/data1.bin ./tmp/data2.bin
```

Если diff ничего не выводит, это значит, что файлы совпадают и тест успешно пройден.

### Простой тест на синхронизацию файлов между несколькими узлами (3 балла, simple-random)

**Timeout: 30 seconds**

Этот тест похож на предыдущий, но его тестирование производится с помощью наших скриптов без участия docker-compose.
Тест запускается несколько раз с разной конфигурацией. В этом тесте гарантируется, что:

- всего есть некоторое количество узлов (контейнеров), от 2 до 10
- в каждом контейнере запускается образ, собранный из папки `./solution`
- контейнер запускается один раз и после этого не останавливается до окончания теста
- в каждом контейнере находится файл `/torrent.conf` с полной информацией
- правильный файл `/data.bin` находится РОВНО на одном узле, на остальных узлах этот файл пустой или его не существует
- размер файла `/data.bin` от 1 килобайта до 1 мегабайта
- размер куска от 128 байт до 4 килобайт

### Простой тест с дополнительными случаями (2 балла, simple-extra)

**Timeout: 60 seconds**

В отличие от предыдущего теста, правильный файл `/data.bin` может находиться больше чем на одном узле. На узлах без
правильного файла никаких гарантий про содержимое файла не дается. Также на узлах без правильного файла массив Peers
может быть пустым. В этом тесте размер файла может достигать 1ГБ, а также может запускаться до 60 узлов. При этом
суммарный размер файлов на всех узлах в большинстве случаев примерно равен 1ГБ, то есть 2ГБ свободного места на диске
должно быть достаточно для запуска этого теста.

### Тест с распределенными кусками (1 балл, many-source)

**Timeout: 30 seconds**

В этом тесте гарантируется, что:

- всего есть некоторое количество узлов (контейнеров), от 4 до 16
- размер файла `/data.bin` от 1МБ до 16МБ
- размер куска от 64кб до 128кб
- в каждом контейнере запускается образ, собранный из папки `./solution`
- контейнер запускается один раз и после этого не останавливается до окончания теста
- в каждом контейнере находится файл `/torrent.conf` с полной информацией
- правильная версия каждого куска находится как минимум на одном узле, то есть для получения правильного файла целиком
  нужно объединить куски со всех узлов

### Тест с перезагрузками (1 балл, restarts)

**Timeout: 120 seconds**

В отличие от предыдущего теста, в этом тесте узлы могут перезагружаться, причем делают это довольно часто. Почти всегда
узлы перезагружаются не чаще чем раз в секунду. Подробная информация про то как именно перезагружаются узлы находится в
файле [/testutil/tasks/restart.go](./testutil/tasks/restart.go).

### Тест с неполной информацией о узлах (1 балл, restarts-discovery)

**Timeout: 120 seconds**

В отличие от предыдущего теста, в этом тесте не на всех узлах есть полная информация в файле `/torrent.conf`.
Гарантируется, что информация про файл (то есть его размер и хеши) находится не менее чем на одном узле. Также
гарантируется что если представить массивы Peers в виде неориентированного графа, он получится связным.

### Тест на обнаружение узлов в сети (1 балл, self-discovery)

**Timeout: 120 seconds**

В отличие от предыдущего теста, в этом тесте все массивы Peers пустые. Гарантируется, что все пиры находятся в одной
подсети "/24".

### Итого

Все тесты должно проходить решение, которое пользуется только этими гарантиями:

- в каждом контейнере запускается образ, собранный из папки `./solution`
- как минимум у одного узла есть информация про файл, у остальных узлов эта информация либо есть, либо нету
- времени достаточно, чтобы синхронизировать файлы
- пакеты в сети не модифицируются
- информации про соседние узлы достаточно, чтобы все узлы знали про все другие узлы, возможно после некоторого общения и
  обмена данными

## Локальный запуск тестов

Нужно установить Go версии 1.17 (но возможно 1.16 тоже подойдет), а также docker и docker-compose.

```bash
docker-compose build

cd testutil
go build ./cmd/grader
cd ..

./testutil/grader
```

`grader` поддерживает несколько удобных флагов для локального запуска:

```bash
# запустить только тесты simple-random и сохранить логи со всех докер контейнеров в папке ./logs
./testutil/grader -filter simple-random -logs ./logs

# более полный скрипт, который собирает код перед запуском теста, а также позволяет избежать проблем с пересозданием сетей
# ОСТОРОЖНО, удаляет все созданные контейнеры
docker rm -f $(docker ps -aq); docker-compose build && ./testutil/grader -filter simple-random -logs ./logs
```

Такой запуск с сохранением логов не работает для первого теста (simple-docker-compose), в этом тесте решение нужно запускать руками через docker-compose, как это сделать написано выше.

## Оценивание

1. (1 балл) Синхронизация одного файла в docker-compose
2. (3 балла) Простой тест на синхронизацию файлов между несколькими узлами (simple-random)
3. (2 балла) Простой тест с дополнительными случаями (simple-extra)
4. (1 балл) Тест с распределенными кусками (many-source)
5. (1 балл) Тест с перезагрузками (restarts)
6. (1 балл) Тест с неполной информацией о узлах (restarts-discovery)
7. (1 балл) Тест на обнаружение узлов в сети (self-discovery)

## Советы по решению

Могут быть полезны если вы пишете решение на питоне и не только.

### Баги в шаблоне

1. В storage.py:48 после `self.file.write(data)` нужно написать `self.file.flush()` чтобы данные сохранились на диске
1. Config.peers может быть `None`, это значит то же что и `[]`
1. Config.file_info.parts также может быть `None`, это тоже значит `[]`
1. class Provider не нужен, можете удалить его

### asyncio

https://docs.python.org/3/library/asyncio-task.html

1. Функции которые объявлены как `async def` называются корутинами или асинхронными функциями.
1. В каждый момент выполняется только одна корутина.
1. Корутины могут переключаться между собой только в момент вызова await/gather и прочих async конструкций.
1. `asyncio.create_task()` нужен чтобы запустить корутину как фоновый процесс.

Если вы вызываете `asyncio.create_task()` в цикле, то нужно где-то сохранить ссылку на задачу чтобы она точно начала запускаться:

```python
pending_tasks_hack = []

for i in range(100):
    task = asyncio.create_task(some_coroutine())
    pending_tasks_hack.append(task)
```

Чтобы вызвать sleep на 1 секунду нужно написать:
```python
await asyncio.sleep(1)
```

Может быть полезно хранить текущее состояние узла в глобальных переменных. К этим переменным почти во всех случаях можно обращаться без блокировок, так как в один момент выполняется только одна корутина.

### asyncio streams (TCP)

https://docs.python.org/3/library/asyncio-stream.html

Чтобы подключиться к другому узлу, нужно написать примерно такой код:
```python
reader, writer = await asyncio.open_connection(peer, port)
task = asyncio.create_task(handle_socket(reader, writer))
```

После установленного соединения у нас есть два объекта: reader и writer. Чтобы закрыть соединение можно вызвать `writer.close()`. Чтобы читать/писать данные:

```python
# Прочитать ровно 16 байт:
buf = await reader.readexactly(16)

# Записать буффер buf
writer.write(buf)
await writer.drain()
```

Может быть полезно узнать адрес и порт узла к которому мы подключились:

```python
peer_ip, port = writer.get_extra_info("peername")
```

### Общие советы про TCP-сокеты в задании

1. Создавать сокет это дорогая и долгая операция. Старайтесь оптимизировать количество созданий сокетов.
1. Логично установить соединение между парой узлов и не закрывать его пока оно может пригодиться.
1. Не нужно одновременно открывать больше одного сокета между двумя узлами. Для этого в Set можно поддерживать множество подключенных на текущий момент узлов.
1. Узлы стартуют не одновременно, поэтому имеет смысл пытаться подключиться к другому узлу пока не получится (но при этом не слишком часто, чтобы не перегружать сеть).

Пример обработки сообщений в TCP соединении:

```python
try:
    await handshake(reader, writer)

    while True:
        msg = await read_message(reader)
        await process_message(msg)
except Exception as e:
    print(e)

writer.close()
await writer.wait_closed()
```

### Пример реализации бинарного протокола

```python
import struct

class Message:
    mtype: int
    data: bytes

# conn_lock это блокировка для соединения, она нужна чтобы мы не вызывали writer.drain() одновременно
# из разных корутин (это приводит к AssertionError)
async def write_message(conn_lock: asyncio.Lock, writer: asyncio.StreamWriter, message: Message) -> None:
    await conn_lock.acquire()
    try:
        if writer.is_closing():
            return
        writer.write(struct.pack('LL', message.mtype, len(message.data)))
        writer.write(message.data)
        await writer.drain()
    except Exception as e:
        print(e)
    finally:
        conn_lock.release()

async def read_message(reader: asyncio.StreamReader, message: Message) -> None:
    buf = await reader.readexactly(16)
    message.mtype, length = struct.unpack('LL', buf)
    message.data = await reader.readexactly(length)
```

### Проблемы с локальным запуском

Может случиться такая ошибка:
```
Running command : docker [network create --internal --subnet 172.20.234.0/24 nets-hw2]
==== 2021/12/04 22:17:56 failed to create networkexit status 1
```

Эта ошибка означает что не удалось создать docker network. Такое может произойти из-за нескольких разных причин, вот список команд которые ЧТО-ТО УДАЛЯЮТ ИЛИ ИЗМЕНЯЮТ, но могут устранить эту проблемы: 

```bash
# ОСТОРОЖНО, это удалит ВСЕ контейнеры
docker rm -f $(docker ps -aq)

# ОСТОРОЖНО, эта команда удалит ВСЕ пользовательские сети
docker network prune -f

# ОСТОРОЖНО, эта команда перезагрузит демон докера (Ubuntu/Linux Systemd)
systemctl restart docker
```

Предупреждения вида `==== 2021/12/05 13:33:10 WARN failed to get digest: exit status 1` обычно означают что контейнер сейчас не запущен. Это могло произойти если программа упала с ошибкой, а также это может быть нормально в тестах с рестартами.



### Работа с Gitlab CI

Если локально все работает, а в CI нет, или просто хочется понимать как оно работает в CI, можно попробовать собирать логи во время запуска CI. Для этого нужно в .gitlab-ci.yml сделать следующую задачу, а все остальные удалить:

```yml
2-torrent:
  image: docker:latest
  stage: test
  services:
    - docker:dind
  before_script:
    # Install docker-compose and go
    - apk add --no-cache docker-compose go git make musl-dev
    - go version
    - docker version
    - docker-compose version
  script:
    - cd 2-torrent/testutil
    - go build cmd/grader/main.go
    - cd ..
    - ./testutil/main -logs ./logs
  rules:
    - changes:
        - 2-torrent/**/*
        - .gitlab-ci.yml
  artifacts:
    untracked: true
```

После завершения пайплайна в CI появится раздел **Job artifacts**, в котором Download позволит загрузить логи в виде архива.

Изменения в .gitlab-ci.yml и прочих тестирующих файлах перед сдачей финального решения нужно откатить.

Если в вашем Merge Request запускаются задачи помимо 2-torrent, то вы скорее всего забыли скачать к себе в репозиторий изменения из upstream/main в origin/main, сделайте git merge.

Если в Gitlab CI не проходят какие-то тесты, когда они проходят локально, это может значить:
- что в решении есть баг, и что локально оно тоже не всегда проходит
- решение использует слишком много ресурсов, открывает много сокетов, использует много CPU/RAM, или посылает много сообщений в сеть

Если ваше решение проходит тесты many-source и restarts, но при этом не проходит simple-extra, то скорее всего вы используете много ресурсов. Ресурсы в CI ограничены, а именно есть какой-то лимит на суммарное количество сокетов во всех узлах. Может произойти ситуация, когда множество узлов открыло между собой n^2 соединений, и новые узлы не могут подключиться ни к каким другим узлам. Если закрывать соединение между полностью синхронизированными пирами (у которых хеши совпадают для всех частей), то это решит эту проблему.

### Прочие вопросы и рекомендации

Крайне рекомендуется сначала написать решение на 6, потом на 8, и только после этого начинать писать что-то сложное, связанное с синхронизацией пиров и информации про файл.
